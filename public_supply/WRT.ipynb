{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feather\n",
    "from pyproj import Proj, transform\n",
    "import calendar as cldr\n",
    "from geopy.geocoders import Nominatim\n",
    "import itertools\n",
    "import addfips\n",
    "import zipcode\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing feather datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PA_VA_FL_df = feather.read_dataframe(\"PA_VA_FL.feather\")\n",
    "NJ_df = feather.read_dataframe(\"NJ.feather\")\n",
    "NJ_loc_df = feather.read_dataframe(\"NJ_loc.feather\")\n",
    "OR_df = feather.read_dataframe(\"OR.feather\")\n",
    "OR_loc_df = feather.read_dataframe(\"OR_loc2.feather\")\n",
    "MD_df = feather.read_dataframe(\"MD.feather\")\n",
    "ID_df = feather.read_dataframe(\"ID.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PA, VA, & FL\n",
    "\n",
    "### Scott Worland compiled the water-use data for PA, VA, and FL into the imported csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PA, VA, and FL Datasets already compiled by Scott Worland\n",
    "# PA_VA_FL_df = pd.read_csv(\"PA_VA_FL\\public_supply_data_pa_va_fl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PA_VA_FL_df[\"uid\"] = PA_VA_FL_df[\"uid\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PVF_df = PA_VA_FL_df.rename(columns={'mgd':'Mg'})\n",
    "\n",
    "FL_df = PVF_df[:].query('state == \"FL\"')\n",
    "VA_df = PVF_df[:].query('state == \"VA\"')\n",
    "PA_df = PVF_df[:].query('state == \"PA\"')\n",
    "\n",
    "feather.write_dataframe(FL_df,\"feather_files\\FL_raw.feather\")\n",
    "feather.write_dataframe(VA_df,\"feather_files\\VA_raw.feather\")\n",
    "feather.write_dataframe(PA_df,\"feather_files\\PA_raw.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FL_df['month'] = FL_df[\"month\"].astype(\"float\")\n",
    "\n",
    "FL_df['date'] = \"\"\n",
    "FL_df[\"Mgd\"]=\"\"\n",
    "\n",
    "FL_df['month'] = FL_df[\"month\"].astype(\"int\")\n",
    "\n",
    "FL_df['date'] = FL_df.apply(lambda x: pd.datetime.strptime(\"{0} {1}\".format(x['month'],x['year']), \"%m %Y\"),axis=1)\n",
    "\n",
    "FL_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "FL_df.rename(columns={'uid': 'id'}, inplace=True)\n",
    "\n",
    "FL_agg=FL_df.groupby(by='id').resample('1AS').sum()\n",
    "\n",
    "FL_agg.drop(['year','month','lat','lon'], inplace=True, axis=1)\n",
    "\n",
    "FL_agg[\"Mgd\"] = FL_agg[\"Mg\"]/FL_agg[\"days\"]\n",
    "\n",
    "FL_agg['State']=\"FL\"\n",
    "\n",
    "FL_agg.reset_index(level=1, inplace=True)\n",
    "\n",
    "FL_xy = FL_df[[\"id\",\"lon\",\"lat\"]]\n",
    "FL_xy.columns=['id','X_WGS','Y_WGS']\n",
    "FL_xy.set_index('id',inplace=True)\n",
    "\n",
    "FL_agg=FL_agg.join(FL_xy, how='inner')\n",
    "\n",
    "FL_agg.reset_index(inplace=True)\n",
    "\n",
    "FL_agg = FL_agg.groupby(['id','date']).first()\n",
    "\n",
    "FL_agg.reset_index(inplace=True)\n",
    "\n",
    "FL_agg.drop('days',1,inplace=True)\n",
    "\n",
    "feather.write_dataframe(FL_agg,\"feather_files\\FL_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VA_df['date'] = \"\"\n",
    "VA_df[\"Mgd\"]=\"\"\n",
    "VA_df[\"days\"]=\"\"\n",
    "\n",
    "VA_df['date'] = VA_df.apply(lambda x: pd.datetime.strptime(\"{0}\".format(x['year']), \"%Y\"),axis=1)\n",
    "\n",
    "VA_df['days']=VA_df.apply(lambda row: cldr.monthrange(row[\"year\"],1)[1]\n",
    "                         +cldr.monthrange(row[\"year\"],2)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],3)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],4)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],5)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],6)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],7)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],8)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],9)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],10)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],11)[1]\n",
    "                          +cldr.monthrange(row[\"year\"],12)[1],axis=1)\n",
    "\n",
    "VA_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "VA_df.rename(columns={'uid': 'id'}, inplace=True)\n",
    "\n",
    "VA_agg=VA_df.groupby(by='id').resample('1AS').sum()\n",
    "\n",
    "VA_agg.drop(['year','month','lat','lon'], inplace=True, axis=1)\n",
    "\n",
    "VA_agg[\"Mgd\"] = VA_agg[\"Mg\"]/VA_agg[\"days\"]\n",
    "\n",
    "VA_agg['State']=\"VA\"\n",
    "\n",
    "VA_agg.reset_index(level=1, inplace=True)\n",
    "\n",
    "VA_xy = VA_df[[\"id\",\"lon\",\"lat\"]]\n",
    "VA_xy.columns=['id','X_WGS','Y_WGS']\n",
    "VA_xy.set_index('id',inplace=True)\n",
    "\n",
    "VA_agg=VA_agg.join(VA_xy, how='inner')\n",
    "\n",
    "VA_agg.reset_index(inplace=True)\n",
    "\n",
    "VA_agg = VA_agg.groupby(['id','date']).first()\n",
    "\n",
    "VA_agg.reset_index(inplace=True)\n",
    "\n",
    "VA_agg.drop('days',1,inplace=True)\n",
    "\n",
    "feather.write_dataframe(VA_agg,\"feather_files\\VA_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PA_df['month'] = PA_df[\"month\"].astype(\"float\")\n",
    "\n",
    "PA_df['date'] = \"\"\n",
    "PA_df[\"Mgd\"]=\"\"\n",
    "\n",
    "PA_df['month'] = PA_df[\"month\"].astype(\"int\")\n",
    "\n",
    "PA_df['date'] = PA_df.apply(lambda x: pd.datetime.strptime(\"{0} {1}\".format(x['month'],x['year']), \"%m %Y\"),axis=1)\n",
    "\n",
    "PA_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "PA_df.rename(columns={'uid': 'id'}, inplace=True)\n",
    "\n",
    "PA_agg=PA_df.groupby(by='id').resample('1AS').sum()\n",
    "\n",
    "PA_agg.drop(['year','month','lat','lon'], inplace=True, axis=1)\n",
    "\n",
    "PA_agg[\"Mgd\"] = PA_agg[\"Mg\"]/PA_agg[\"days\"]\n",
    "\n",
    "PA_agg['State']=\"PA\"\n",
    "\n",
    "PA_agg.reset_index(level=1, inplace=True)\n",
    "\n",
    "PA_xy = PA_df[[\"id\",\"lon\",\"lat\"]]\n",
    "PA_xy.columns=['id','X_WGS','Y_WGS']\n",
    "PA_xy.set_index('id',inplace=True)\n",
    "\n",
    "PA_agg=PA_agg.join(PA_xy, how='inner')\n",
    "\n",
    "PA_agg.reset_index(inplace=True)\n",
    "\n",
    "PA_agg = PA_agg.groupby(['id','date']).first()\n",
    "\n",
    "PA_agg.reset_index(inplace=True)\n",
    "\n",
    "PA_agg.drop('days',1,inplace=True)\n",
    "\n",
    "feather.write_dataframe(PA_agg,\"feather_files\\PA_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quantity\n",
    "OR_df = pd.read_excel(\"OR\\OWRD_PS_water_use.xlsx\")\n",
    "\n",
    "# Location\n",
    "OR_loc_df = pd.read_excel(r\"OR\\OR_locations_merged.xlsx\")\n",
    "\n",
    "feather.write_dataframe(OR_df,\"feather_files\\OR_raw.feather\")\n",
    "feather.write_dataframe(OR_loc_df,\"feather_files\\OR_locations_raw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OR_df['month']=\"\"\n",
    "OR_df['year']=\"\"\n",
    "OR_df['date'] = \"\"\n",
    "OR_df['days'] = \"\"\n",
    "OR_df[\"Mgd\"]=\"\"\n",
    "OR_df[\"Mg\"]=\"\"\n",
    "\n",
    "def wtr_month_to_month(row):\n",
    "    if row['water_month'] >3:\n",
    "        return row['water_month']-3\n",
    "    else:\n",
    "        return row['water_month'] + 9\n",
    "    \n",
    "def wtr_yr_to_yr(row):\n",
    "    if row['water_month'] <4:\n",
    "        return row['water_year']-1\n",
    "    else:\n",
    "        return row['water_year']\n",
    "\n",
    "OR_df.month = OR_df.apply(lambda row: wtr_month_to_month(row), axis=1)\n",
    "\n",
    "OR_df.year = OR_df.apply(lambda row: wtr_yr_to_yr(row), axis=1)\n",
    "\n",
    "OR_df['date'] = OR_df.apply(lambda x: pd.datetime.strptime(\"{0} {1}\".format(x['month'],x['year']), \"%m %Y\"),axis=1)\n",
    "\n",
    "OR_df[\"days\"] = OR_df.apply(lambda row: cldr.monthrange(row[\"year\"],row[\"month\"])[1],axis=1)\n",
    "\n",
    "OR_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "OR_agg=OR_df.resample('1AS').sum()\n",
    "\n",
    "OR_agg=OR_df.groupby(by='wur_report_id').resample('1AS').sum()\n",
    "OR_agg[\"Mg\"] = OR_agg[\"water_used (acre feet)\"]*325851/1000000\n",
    "OR_agg[\"Mgd\"] = OR_agg[\"Mg\"]/OR_agg[\"days\"]\n",
    "\n",
    "OR_agg.drop(['month','year','water_month','water_year','wur_report_id','water_used (acre feet)'],1,inplace=True)\n",
    "\n",
    "OR_agg['State']=\"OR\"\n",
    "\n",
    "OR_agg.index.names=['id','date']\n",
    "\n",
    "OR_loc_df = OR_loc_df.rename(columns={'wur_report_id':'id'})\n",
    "\n",
    "OR_loc_df = OR_loc_df[['id','X_WGS','Y_WGS']]\n",
    "\n",
    "OR_agg.reset_index(inplace=True)\n",
    "\n",
    "OR_loc_df.reset_index(inplace=True)\n",
    "\n",
    "OR_agg = OR_agg.merge(OR_loc_df, on='id')\n",
    "\n",
    "OR_agg.drop(['index','days'],1,inplace=True)\n",
    "\n",
    "feather.write_dataframe(OR_agg,\"feather_files\\OR_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Quantity\n",
    "# NJ_df = pd.read_excel(\"NJ\\Withdrawals by HUC.xlsx\")\n",
    "\n",
    "# # Location\n",
    "# NJ_loc_df = pd.read_excel(r\"NJ\\NJ_PS_location_data.xlsx\")\n",
    "\n",
    "# feather.write_dataframe(NJ_df,r\"feather_files\\NJ_raw.feather\")\n",
    "# feather.write_dataframe(NJ_loc_df,r\"feather_files\\NJ_locations_raw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NJ_df = feather.read_dataframe(r\"feather_files\\NJ.feather\")\n",
    "NJ_loc_df = feather.read_dataframe(r\"feather_files\\NJ_locations.feather\")\n",
    "\n",
    "NJ_df['month']=\"\"\n",
    "NJ_df['year']=\"\"\n",
    "NJ_df['date'] = \"\"\n",
    "NJ_df['days'] = \"\"\n",
    "NJ_df[\"Mgd\"]=\"\"\n",
    "\n",
    "NJ_df['date'] = NJ_df.apply(lambda x: pd.datetime.strptime(\"{0} {1}\".format(x['Month'],x['Year']), \"%m %Y\"),axis=1)\n",
    "\n",
    "NJ_df[\"days\"] = NJ_df.apply(lambda row: cldr.monthrange(row[\"Year\"],row[\"Month\"])[1],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "NJ_df.set_index('date', inplace=True)\n",
    "\n",
    "NJ_agg=NJ_df.resample('1AS').sum()\n",
    "\n",
    "NJ_agg=NJ_df.groupby(by='SiteName').resample('1AS').sum()\n",
    "\n",
    "NJ_agg[\"Mgd\"] = NJ_agg[\"WithdrawalMG\"]/NJ_agg[\"days\"]\n",
    "\n",
    "NJ_agg.drop(['Month','Year','HUC14','days'],1,inplace=True)\n",
    "\n",
    "NJ_agg['State']=\"NJ\"\n",
    "\n",
    "NJ_agg.index.names=['id','date']\n",
    "\n",
    "NJ_agg.columns=[['Mg', 'Mgd', 'State']]\n",
    "\n",
    "outProj = Proj(init='epsg:4326')\n",
    "\n",
    "#NJ\n",
    "NJinProj = Proj(init='epsg:3424')\n",
    "x,y = NJ_loc_df[\"NJEasting\"].values,NJ_loc_df[\"NJNorthing\"].values\n",
    "NJ_loc_df[\"X_WGS\"],NJ_loc_df[\"Y_WGS\"] = transform(NJinProj,outProj,x,y)\n",
    "\n",
    "NJ_xy = NJ_loc_df[[\"SiteName\",\"X_WGS\",\"Y_WGS\"]]\n",
    "NJ_xy.columns=['id','X_WGS','Y_WGS']\n",
    "NJ_xy.set_index('id',inplace=True)\n",
    "\n",
    "NJ_agg=NJ_agg.join(NJ_xy, how='inner')\n",
    "\n",
    "NJ_agg.reset_index(inplace=True)\n",
    "\n",
    "feather.write_dataframe(NJ_agg,r\"feather_files\\NJ_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Quantity & location\n",
    "MD_df = pd.read_excel(\"MD\\ScottWorland-Allsites-monthly-withdrawals-Maryland.xlsx\")\n",
    "\n",
    "feather.write_dataframe(MD_df,r\"feather_files\\MD_raw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MD_df['Mg']=\"\"\n",
    "MD_df['Mg'] = MD_df.apply(lambda row: row['January Value']*cldr.monthrange(row[\"Year\"],1)[1]\n",
    "            +row['February Value']*cldr.monthrange(row[\"Year\"],2)[1]\n",
    "            +row['March Value']*cldr.monthrange(row[\"Year\"],3)[1]\n",
    "            +row['April Value']*cldr.monthrange(row[\"Year\"],4)[1]\n",
    "            +row['May Value']*cldr.monthrange(row[\"Year\"],5)[1]\n",
    "            +row['June Value']*cldr.monthrange(row[\"Year\"],6)[1]\n",
    "            +row['July Value']*cldr.monthrange(row[\"Year\"],7)[1]\n",
    "            +row['August Value']*cldr.monthrange(row[\"Year\"],8)[1]\n",
    "            +row['September Value']*cldr.monthrange(row[\"Year\"],9)[1]\n",
    "            +row['October Value']*cldr.monthrange(row[\"Year\"],10)[1]\n",
    "            +row['November Value']*cldr.monthrange(row[\"Year\"],11)[1]\n",
    "            +row['December Value']*cldr.monthrange(row[\"Year\"],12)[1],axis=1)\n",
    "\n",
    "MD_df['date'] = \"\"\n",
    "\n",
    "MD_df['date'] = MD_df.apply(lambda x: pd.datetime.strptime(\"{0}\".format(x['Year']), \"%Y\"),axis=1)\n",
    "\n",
    "MD_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "MD_df.rename(columns={'From Decimal Latitude': 'Y_WGS', 'From Decimal Longitude': 'X_WGS', 'Annual Value': 'Mgd','From Site Number': 'id'}, inplace=True)\n",
    "\n",
    "MD_agg=MD_df.groupby(by='id').resample('1AS').sum()\n",
    "\n",
    "MD_agg = MD_agg[['Y_WGS', 'X_WGS', 'Mgd','Mg']]\n",
    "\n",
    "MD_agg['State']=\"MD\"\n",
    "\n",
    "MD_agg.reset_index(inplace=True)\n",
    "\n",
    "feather.write_dataframe(MD_agg,r\"feather_files\\MD_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_df = pd.read_excel(\"ID\\Idaho-monthly-SWUDS-data.xlsx\")\n",
    "ID_df[\"FROM_COORD_ACY_CD\"] = ID_df[\"FROM_COORD_ACY_CD\"].astype(\"str\")\n",
    "ID_df[\"FROM_ALT_VA\"] = ID_df[\"FROM_ALT_VA\"].astype(\"str\")\n",
    "ID_df[\"FROM_ALT_ACY_VA\"] = ID_df[\"FROM_ALT_ACY_VA\"].astype(\"str\")\n",
    "\n",
    "feather.write_dataframe(ID_df,r\"feather_files\\ID_raw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_df['Mg']=\"\"\n",
    "ID_df['Mgd']=\"\"\n",
    "ID_df['Mg'] = ID_df.apply(lambda row: row['JAN_VAL']*cldr.monthrange(row[\"YEAR\"],1)[1]\n",
    "            +row['FEB_VAL']*cldr.monthrange(row[\"YEAR\"],2)[1]\n",
    "            +row['MAR_VAL']*cldr.monthrange(row[\"YEAR\"],3)[1]\n",
    "            +row['APR_VAL']*cldr.monthrange(row[\"YEAR\"],4)[1]\n",
    "            +row['MAY_VAL']*cldr.monthrange(row[\"YEAR\"],5)[1]\n",
    "            +row['JUN_VAL']*cldr.monthrange(row[\"YEAR\"],6)[1]\n",
    "            +row['JUL_VAL']*cldr.monthrange(row[\"YEAR\"],7)[1]\n",
    "            +row['AUG_VAL']*cldr.monthrange(row[\"YEAR\"],8)[1]\n",
    "            +row['SEP_VAL']*cldr.monthrange(row[\"YEAR\"],9)[1]\n",
    "            +row['OCT_VAL']*cldr.monthrange(row[\"YEAR\"],10)[1]\n",
    "            +row['NOV_VAL']*cldr.monthrange(row[\"YEAR\"],11)[1]\n",
    "            +row['DEC_VAL']*cldr.monthrange(row[\"YEAR\"],12)[1], axis=1)\n",
    "\n",
    "ID_df['date'] = \"\"\n",
    "\n",
    "ID_df['Mgd']=ID_df['Mg']/ID_df.apply(lambda row: cldr.monthrange(row[\"YEAR\"],1)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],2)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],3)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],4)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],5)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],6)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],7)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],8)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],9)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],10)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],11)[1]\n",
    "            +cldr.monthrange(row[\"YEAR\"],12)[1],axis=1)\n",
    "\n",
    "ID_df['date'] = ID_df.apply(lambda x: pd.datetime.strptime(\"{0}\".format(x['YEAR']), \"%Y\"),axis=1)\n",
    "\n",
    "ID_df.set_index(\"date\",inplace=True)\n",
    "\n",
    "ID_df.rename(columns={'FROM_DEC_LAT_VA': 'Y_WGS', 'FROM_DEC_LONG_VA': 'X_WGS','SITE_NO': 'id'}, inplace=True)\n",
    "\n",
    "ID_agg=ID_df[['Mgd','Mg','id']].groupby(by='id').resample('1AS').sum()\n",
    "\n",
    "ID_agg.drop('id',1, inplace=True)\n",
    "\n",
    "ID_agg['State']=\"ID\"\n",
    "\n",
    "ID_df.reset_index(inplace=True)\n",
    "ID_xy = ID_df[['Y_WGS', 'X_WGS','id','date']].groupby(['id','date']).first()\n",
    "\n",
    "ID_agg = ID_agg.join(ID_xy, how='inner')\n",
    "\n",
    "ID_agg.reset_index(inplace=True)\n",
    "\n",
    "feather.write_dataframe(ID_agg,r\"feather_files\\ID_agg.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending All States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mg</th>\n",
       "      <th>Mgd</th>\n",
       "      <th>State</th>\n",
       "      <th>X_WGS</th>\n",
       "      <th>Y_WGS</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.078542</td>\n",
       "      <td>0.117504</td>\n",
       "      <td>OR</td>\n",
       "      <td>45.287654</td>\n",
       "      <td>-117.220473</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.754025</td>\n",
       "      <td>0.190439</td>\n",
       "      <td>OR</td>\n",
       "      <td>45.287654</td>\n",
       "      <td>-117.220473</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.405490</td>\n",
       "      <td>0.134988</td>\n",
       "      <td>OR</td>\n",
       "      <td>45.287654</td>\n",
       "      <td>-117.220473</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.429652</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>OR</td>\n",
       "      <td>45.287654</td>\n",
       "      <td>-117.220473</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360.732903</td>\n",
       "      <td>1.190538</td>\n",
       "      <td>OR</td>\n",
       "      <td>45.287654</td>\n",
       "      <td>-117.220473</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mg       Mgd State      X_WGS       Y_WGS       date     id\n",
       "0   32.078542  0.117504    OR  45.287654 -117.220473 2002-01-01  10591\n",
       "1   40.754025  0.190439    OR  45.287654 -117.220473 2003-01-01  10591\n",
       "2   49.405490  0.134988    OR  45.287654 -117.220473 2004-01-01  10591\n",
       "3  180.429652  0.494328    OR  45.287654 -117.220473 2005-01-01  10591\n",
       "4  360.732903  1.190538    OR  45.287654 -117.220473 2006-01-01  10591"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WU_app = OR_agg\n",
    "WU_app = WU_app.append([PA_agg, VA_agg, FL_agg, ID_agg, MD_agg, NJ_agg])\n",
    "WU_app['id'] = WU_app['id'].astype(\"str\")\n",
    "feather.write_dataframe(WU_app,r\"feather_files\\WaterUse_aggregated.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B25034_010E': '282894', 'NAME': 'Maryland', 'state': '24'}]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "c = Census(\"fc32091d4f678e7d558e04351b3dc5f3ebb090e9\")\n",
    "# c.acs5.get(('NAME', 'B25034_010E'),\n",
    "#           {'for': 'state:{}'.format(states.MD.fips)})\n",
    "\n",
    "c.acs5.state(('NAME', 'B25034_010E'), states.MD.fips, year=2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling County and FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "# location = geolocator.reverse(list(zip(OR_df[\"X_WGS\"],OR_df[\"Y_WGS\"]))).raw['address']['county']\n",
    "# print(location.raw['address']['county'])\n",
    "x = list(zip(OR_df[\"X_WGS\"],OR_df[\"Y_WGS\"]))\n",
    "fips = addfips.AddFIPS()\n",
    "OR_df['County']=\"\"\n",
    "OR_df['zipcode']=\"\"\n",
    "OR_df['cnty_fip']=\"\"\n",
    "\n",
    "# for index, row in OR_df.iterrows():\n",
    "#     row[\"County\"] = lambda row: geolocator.reverse(zip(row[\"X_WGS\"],row[\"Y_WGS\"])).raw['address']['county']\n",
    "#Then call addfips to attribute FIPS code to each county\n",
    "# print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-7f57d189ca2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOR_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mOR_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cnty_fip\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfips\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_county_fips\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"county\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'State'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in OR_df.iterrows():\n",
    "    OR_df[\"cnty_fip\"] = fips.get_county_fips(row[\"county\"], row['State']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41017'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips.get_county_fips(OR_df[\"county\"][1], OR_df['State'][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lambdazipcode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-dea4ab555ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOR_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mOR_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zipcode\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlambdazipcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinradius\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X_WGS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Y_WGS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lambdazipcode' is not defined"
     ]
    }
   ],
   "source": [
    "for index, row in OR_df.iterrows():\n",
    "    OR_df[\"zipcode\"] = zipcode.isinradius(zip(row[\"X_WGS\"],row[\"Y_WGS\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting as feather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 13-14: malformed \\N character escape (<ipython-input-84-c8d14b534973>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-c8d14b534973>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    feather.write_dataframe(NJ_agg,\"feather_files\\NJ.feather\")\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 13-14: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "feather.write_dataframe(PA_VA_FL_df,\"feather_files\\PA_VA_FL.feather\")\n",
    "feather.write_dataframe(NJ_agg,\"feather_files\\NJ.feather\")\n",
    "feather.write_dataframe(NJ_df,\"feather_files\\NJ.feather\")\n",
    "feather.write_dataframe(NJ_loc_df,\"feather_files\\NJ_loc.feather\")\n",
    "feather.write_dataframe(OR_agg,\"feather_files\\OR.feather\")\n",
    "feather.write_dataframe(OR_df,\"OR.feather\")\n",
    "feather.write_dataframe(OR_loc_df,\"feather_files\\OR_loc2.feather\")\n",
    "feather.write_dataframe(MD_agg2,\"feather_files\\MD.feather\")\n",
    "feather.write_dataframe(MD_df,\"feather_files\\MD.feather\")\n",
    "feather.write_dataframe(ID_df,\"feather_files\\ID.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
